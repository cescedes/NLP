{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing\n",
    "\n",
    "## Exercise Sheet 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports for all exercises\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Write a program to initialize a two-dimensional array of sets called `word_vowels` and process a list of words, adding each word to `word_vowels[l][v]` where $l$ is the length of the word and $v$ is the number of vowels it contains. Test your program with a 10x10-array and the list `['Alice', 'hat', 'heute', 'ihren', 'freien', 'Tag']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length=3, Vowels=1: {'Tag', 'hat'}\n",
      "Length=5, Vowels=2: {'ihren'}\n",
      "Length=5, Vowels=3: {'heute', 'Alice'}\n",
      "Length=6, Vowels=3: {'freien'}\n"
     ]
    }
   ],
   "source": [
    "word_vowels = [[set() for _ in range(10)] for _ in range(10)]\n",
    "\n",
    "word_list = ['Alice', 'hat', 'heute', 'ihren', 'freien', 'Tag']\n",
    "\n",
    "for word in word_list:\n",
    "    l = len(word)\n",
    "    v = sum(1 for char in word if char in 'aeiouAEIOU')\n",
    "    word_vowels[l][v].add(word)\n",
    "\n",
    "for l in range(10):\n",
    "    for v in range(10):\n",
    "        words = word_vowels[l][v]\n",
    "        if words:\n",
    "            print(f'Length={l}, Vowels={v}: {words}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Write a program that prints all words that only appear in the last 10\\% of a text. Test your code with the file `'shakespeare-macbeth.txt'` from the Gutenberg Corpus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words that only appear in the last 10% of the text:\n",
      "{\"bear't\", 'bloodier', 'Heere', 'alowd', 'Mes', 'Exeunt', 'expence', 'I', 'Friends', 'Which', 'young', 'met', 'Foole', 'her', 'Cyme', 'till', 'what', 'vnshrinking', 'Or', 'Worthy', 'OF', 'art', 'heere', 'FINIS', 'Chambers', 'which', 'haires', 'vulnerable', 'Fare', 'Quarta', 'Will', 'Keepes', 'Fooles', 'Tyrants', 'Scena', 'after', 'liues', 'almost', 'gently', 'inuite', 'Before', \"Pull't\", 'Sun', 'missing', 'vnsure', 'Childrens', 'rendred', 'She', 'souldiers', 'Feares', 'hang', 'thee', 'Wife', 'Enter', 'begge', 'taste', 'before', 'auouches', 'wish', 'euen', 'familiar', 'Sexta', 'bought', 'The', 'beside', 'Now', 'God', 'sound', 'euery', 'aduantage', \"seru'd\", 'here', 'bleed', 'Omnes', 'throw', 'morrow', 'Tell', 'let', 'Erre', 'scowre', \"was't\", 'proue', 'planted', 'worthy', 'Were', 'things', 'fall', 'brauely', 'noyse', 'with', 'measure', 'vnbattered', 'Vsurpers', 'whose', 'like', 'well', 'Sold', 'Septima', 'fearefull', 'Are', 'Iugling', 'giuen', 'calling', 'Groue', 'soule', 'applaud', 'noise', 'impresse', 'from', 'three', 'sides', 'put', 'one', 'Tooke', 'euent', 'field', 'smile', 'my', 'leauy', 'If', 'Cosin', 'get', 'moue', 'mouing', 'Ring', 'will', 'Castle', 'laugh', 'giue', 'Thanes', 'safe', 'hurts', 'an', 'finde', 'name', 'Ague', ']', 'beaten', 'it', 'There', 'promise', 'Here', 'at', 'toward', 'himselfe', 'Roman', 'they', 'sences', 'aliue', 'owe', 'lies', 'feare', 'keene', 'Scone', 'Quinta', 'My', 'be', 'fighting', 'Villaine', 'note', 'must', 'could', 'of', 'Shall', 'hoter', 'Profit', 'might', 'ript', 'Though', 'comming', 'there', 'sence', \"'T\", 'Harbingers', 'reckon', 'yet', 'mee', 'better', 'Macd', 'Souldier', 'world', 'Would', 'That', 'Vntimely', 'wee', 'Fighting', 'cry', 'Am', 'for', 'ground', 'Can', 'l', 'pronounce', 'blow', 'Player', 'dismall', 'worth', 'great', 'kisse', 'owne', 'the', 'women', 'thereby', 'voice', 'MACBETH', 'warre', 'people', 'Vpon', 'good', 'flye', 'vnder-writ', 'marching', 'Y.Sey', 'Till', \"hear'st\", 'vse', 'to', 'numbers', '&', 'Sword', \"com'st\", 'Weapons', 'euer', 'neere', 'as', 'blood', 'large', 'cheapely', 'hatefull', 'Kinsmen', 'Hee', 'breath', 'shadow', 'outward', \"n't\", 'diuell', 'each', 'Ile', 'continued', 'then', 'walking', 'Then', 'Whom', 'King', 'how', 'Gracious', 'Tree', 'Rosse', 'Earles', 'wrath', 'Cathnes', 'Coward', 'done', 'cleere', 'What', \"cool'd\", 'cruell', 'beene', 'Equiuocation', 'sorrow', 'easie', 'rowze', 'Angell', 'Fiends', 'Those', 'compast', 'life', 'men', \"'\", 'can', 'houre', 'are', 'thy', 'Turne', 'Drumme', 'whom', 'other', \"dy'de\", 'Night-shrieke', 'Let', 'strength', 'charmed', 'haunt', 'haire', 'not', 'eare', 'Banners', 'Sonne', 'appeare', 'Yet', 'damn', 'by', 'lesse', 'such', 'Painted', 'voyces', 'lyest', 'had', 'watch', 'heereafter', 'keepe', 'salutation', 'thine', \"Thou'lt\", 'Sonnes', 'Cow', 'start', 'stroake', 'loosest', 'greatest', 'Why', 'a', 'still', 'saw', 'no', 'he', 'exil', 'face', 'Honor', 'call', 'pull', 'Make', ':', 'Malc', 'Industrious', 'Hill', 'Shadow', 'Malcolm', \"'d\", 'nothing', 'Flourish', 'little', 'liue', 'Syllable', 'free', 'certaine', 'none', \"o'th\", 'Alarums', 'cling', 'Royall', 'fury', 'Told', 'hast', 'Foes', 'Mothers', 'blade', 'Malcolme', 'Staues', 'play', 'clatter', 'stand', 'tarrying', 'make', 'last', 'Accursed', 'word', 'Seyward', 'backe', 'lighted', 'Winde', 'Sey', 'yours', 'these', 'speech', 'struts', \"knoll'd\", 'Who', 'beest', 'Malcolmes', 'baited', ';', 'man', 'them', 'night', 'bruited', 'need', 'full', 'Wee', 'hence', 'flying', 'order', 'Wherefore', 'a-weary', 'beare', 'English', 'true', 'vndeeded', 'stands', 'thankes', 'shall', 'newer', 'Famine', 'borne', 'cause', 'Grace', 'Mile', 'Lyar', \"doo't\", 'many', 'dead', 'Whose', 'home', 'Boughes', 'you', 'More', 'part', 'Alarum', 'misse', 'frets', 'or', \"call'st\", 'Our', 'oppos', 'Haile', 'decision', 'Trumpets', 'Retreat', 'off', 'Lord', 'cursed', 'hands', 'pace', 'clamorous', 'Prowesse', 'spend', 'so', 'Warre', 'gaze', 'Treatise', 'Women', 'Ghosts', 'Hoast', 'beard', 'slaine', 'see', 'We', 'In', 'Gods', 'Preparation', 'Tale', 'Rabbles', 'Soldier', \"arriu'd\", 'score', 'Macbeth', 'scorne', 'ha', 'Seyton', 'curse', 'againe', 'Stage', 'Ideot', 'Kernes', 'stake', 'hell', 'in', 'were', 'false', 'loues', 'setting', 'Out', 'Signifying', 'Monsters', 'absent', 'Woman', 'As', 'Th', 'comfort', 'All', 'slaughterous', 'if', 'station', 'Rubarb', 'Candle', 'Thou', \"if't\", 'first', 'heare', 'Knell', 'Queene', 'Doct', \"befor't\", 'minds', 'Souldiership', 'Recorded', 'You', 'armes', 'haue', 'place', 'more', 'No', 'Fiend', 'sooner', 'but', 'next', 'Forrest', 'Producing', 'Purgatiue', 'time', 'petty', 'course', 'tearmes', 'iust', 'day', 'abhorred', 'would', 'either', 'their', 'hope', \"speak'st\", 'anon', 'body', 'our', \"confirm'd\", 'enough', 'Ministers', 'indure', 'draw', 'him', 'walls', 'confident', 'Army', 'fight', 'go', 'onely', 'watchfull', 'According', 'tongue', 'seuerall', 'Angus', 'Brandish', 'tels', 'A', 'Scotland', 'Wood', 'backward', 'Battell', 'Butcher', 'Henceforth', 'was', 'Exit', 'this', 'speak', 'tied', 'auoyded', 'Both', '.', 'gashes', 'Makes', 'Cosins', 'i', 'mine', 'Shield', 'that', 'learne', 'words', 'due', 'dost', 'wracke', 'sir', 'dusty', \"may'st\", 'else', 'power', 'Beare-like', 'Tyrant', 'hand', 'comes', 'Reuolt', 'Fortune', 'breake', 'Macbeths', 'truth', 'vndon', 'Messenger', 'professes', 'They', \"charg'd\", 'approaches', 'though', 'strike', 'Fiend-like', 'Snares', 'Well', 'So', 'To', \"'t\", ')', 'sooth', 'Bell', 'hyr', 'Feare', 'This', 'labour', 'THE', 'Noble', 'Macb', 'Bane', 'abroad', 'fled', 'By', 'on', 'both', 'stirre', 'He', 'darefull', 'turne', 'warlike', 'Towards', 'Fight', 'your', 'At', 'edge', 'once', 'Seemes', \"should'st\", 'speake', 'Crown', 'take', 'rarer', 'begin', 'doubt', 'Story', 'Your', 'issue', 'care', 'For', 'Blood', 'parted', 'debt', 'Behold', 'forth', 'Marching', 'Drum', 'beate', 'performe', 'Harnesse', 'Leade', 'speculatiue', 'vp', 'Skreenes', 'double', 'Vnkle', 'forc', 'Syw', 'Hell-hound', 'now', 'newly', 'th', 'Macduffe', 'liu', 'is', 'quickly', 'And', '(', 'Seyw', 'It', 'Tyranny', 'affraid', 'intrenchant', 'Of', 'breefe', 'maine', 'Within', 'try', 'Menteth', 'fought', 'Censures', 'whiles', 'cries', 'paid', 'stroakes', 'Fell', 'supt', 'feet', \"'s\", 'forgot', 'Cry', 'discouery', 'way', 'something', 'Slaue', 'already', 'Lay', 'brought', 'Creepes', 'woman', 'come', 'Pearle', 'report', 'hopes', 'Charme', '[', 'desire', 'Colours', 'all', 'right', 'downe', 'began', 'Dispaire', 'death', 'say', 'TRAGEDIE', 'within', 'ours', 'nor', 'Hang', 'Attend', 'where', 'measur', 'Crests', 'fairer', 'beleeu', 'know', 'poore', 'least', 'son', 'yeeld', 'Seywards', 'and', 'Bring', 'wood', 'heard', 'drugge', 'y', 'selfe', 'look', 'serue', 'Such', 'being', 'Front', '?', 'Birnane', 'hardly', 'estate', 'thou', 'vs', \"'ginne\", 'out', 'lye', 'any', 'Bough', 'his', 'Souldiers', 'Sir', 'away', 'hold', 'thought', 'Life', 'yesterdayes', 'thoughts', 'Tongue', 'Castles', 'Some', 'Dunsinane', 'Death', 'me', 'Do', 'Ment', 'do', 'aduance', 'we', 'Soldiers', 'head', 'remaines', 'palter', 'Arme', 'Resolution', 'Direnesse', 'Title', ',', 'eate', 'But', 'much', 'dye', 'm', 'hath', 'Byrnane', 'Mal', 'those', 'Ayre', 'did', 'endure', 'arbitrate', 'vpon', 'relate', 'Comes', 'shew', 'may', 'dayes', 'pole', 'Swords', 'wretched', 'On', 'violent', 'hew', 'nam', 'sheath', 'hearts', 'womb', 'end', 'Thoughts', 'Must', 'Kingdomes', 'Siedge', 'should', 'With', 'too', 'Had', 'sword', 'constrained', 'horrors'}\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# load 'shakespeare-macbeth.txt' file\n",
    "macbeth_text = nltk.corpus.gutenberg.raw('shakespeare-macbeth.txt')\n",
    "\n",
    "# tokenize the text into words\n",
    "words = nltk.word_tokenize(macbeth_text)\n",
    "\n",
    "# calculate the index representing the start of the last 10% of the text\n",
    "last_10_percent_index = int(0.9 * len(words))\n",
    "\n",
    "last_10_percent_words = set(words[last_10_percent_index:])    # the words from the last 10% of the text\n",
    "all_words = set(words)    # all unique words from the entire text\n",
    "\n",
    "# find words that only appear in the last 10% of the text\n",
    "unique_last_10_percent_words = last_10_percent_words - (all_words - last_10_percent_words)\n",
    "\n",
    "print(\"Words that only appear in the last 10% of the text:\")\n",
    "print(unique_last_10_percent_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "Write a program that takes a sentence expressed as a single string, splits it and counts up the words. Get it to print out each word and the word's frequency, one per line, in alphabetical order. Test it with the sentence: `'das ist heute wieder einmal wirklich ein sehr sch√∂ner tag das kann ich dir wieder einmal sagen'`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "das: 2\n",
      "dir: 1\n",
      "ein: 1\n",
      "einmal: 2\n",
      "heute: 1\n",
      "ich: 1\n",
      "ist: 1\n",
      "kann: 1\n",
      "sagen: 1\n",
      "sch√∂ner: 1\n",
      "sehr: 1\n",
      "tag: 1\n",
      "wieder: 2\n",
      "wirklich: 1\n"
     ]
    }
   ],
   "source": [
    "sentence = 'das ist heute wieder einmal wirklich ein sehr sch√∂ner tag das kann ich dir wieder einmal sagen'\n",
    "\n",
    "words = sentence.lower().split()  # split the sentence into words and convert to lowercase\n",
    "word_freq = {} # create a frequency dictionary for words\n",
    "\n",
    "# count up the words\n",
    "for word in words:\n",
    "    if word in word_freq:\n",
    "        word_freq[word] += 1\n",
    "    else:\n",
    "        word_freq[word] = 1\n",
    "\n",
    "# print out each word and the word's frequency in alphabetical order\n",
    "for word in sorted(word_freq.keys()):\n",
    "    print(f'{word}: {word_freq[word]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "Write a function `sort_dist(candidates, target)`. The `candidates` are a list of strings representing WordNet synset names, and `target` a synset name string. The function shall sort the `candidates` for proximity to the `target` synset using `shortest_path_distance()`. \n",
    "\n",
    "Test your function with `candidates=['minke_whale.n.01','orca.n.01','novel.n.01', 'tortoise.n.01']` and `target='right_whale.n.01'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted candidates based on proximity to the target synset:\n",
      "['minke_whale.n.01', 'orca.n.01', 'tortoise.n.01', 'novel.n.01']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "def sort_dist(candidates, target):\n",
    "    # calculate the shortest path distances for each candidate to the target synset\n",
    "    distances = [(candidate, wn.synset(candidate).shortest_path_distance(wn.synset(target)))\n",
    "                 for candidate in candidates]\n",
    "\n",
    "    # sort candidates based on shortest path distances (in ascending order)\n",
    "    sorted_candidates = sorted(distances, key=lambda x: x[1])\n",
    "\n",
    "    # extract only the synset names from the sorted list\n",
    "    sorted_synsets = [synset for synset, distance in sorted_candidates]\n",
    "\n",
    "    return sorted_synsets\n",
    "\n",
    "candidates = ['minke_whale.n.01', 'orca.n.01', 'novel.n.01', 'tortoise.n.01']\n",
    "target = 'right_whale.n.01'\n",
    "\n",
    "sorted_synsets = sort_dist(candidates, target)\n",
    "print(\"Sorted candidates based on proximity to the target synset:\")\n",
    "print(sorted_synsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "Write a recursive function `lookup(trie, key)` that looks up a `key` in a `trie`, and returns the value it finds. The function should cover the following cases:\n",
    "\n",
    "a) it should return a corresponding message if the key is not included in the trie;  \n",
    "b) it should return a message if the key is not unique, i.e. if there are several words for this prefix;  \n",
    "c) if a word is uniquely determined by the key prefix it should be returned as result. \n",
    "\n",
    "Try your function for the following trie and test cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'c': {'h': {'a': {'i': {'r': {'value': 'flesh'}},\n",
      "                   't': {'value': 'cat'}},\n",
      "             'e': {'v': {'a': {'l': {'value': 'horse'}}}},\n",
      "             'i': {'c': {'value': 'stylish'},\n",
      "                   'e': {'n': {'value': 'dog'}}}}}}\n"
     ]
    }
   ],
   "source": [
    "def insert(trie, key, value):\n",
    "    if key:\n",
    "        first, rest = key[0], key[1:]\n",
    "        if first not in trie:\n",
    "            trie[first] = {}\n",
    "        insert(trie[first], rest, value)\n",
    "    else:\n",
    "        trie['value'] = value\n",
    "\n",
    "trie = {}\n",
    "insert(trie, 'chat', 'cat')\n",
    "insert(trie, 'chien', 'dog')\n",
    "insert(trie, 'chair', 'flesh')\n",
    "insert(trie, 'chic', 'stylish')\n",
    "insert(trie, 'cheval','horse') \n",
    "trie = dict(trie)             \n",
    "pprint.pprint(trie, width=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup(trie, key):\n",
    "    if not key:\n",
    "        if 'value' in trie:\n",
    "            return trie['value']\n",
    "        else:\n",
    "            return \"Key is not unique.\"\n",
    "    \n",
    "    first, rest = key[0], key[1:]\n",
    "    \n",
    "    if first in trie:\n",
    "        return lookup(trie[first], rest)\n",
    "    else:\n",
    "        return \"Key not found in the trie.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n",
      "Key is not unique.\n",
      "Key not found in the trie.\n",
      "horse\n",
      "Key is not unique.\n",
      "Key is not unique.\n"
     ]
    }
   ],
   "source": [
    "print(lookup(trie, 'chat'))\n",
    "print(lookup(trie, 'cha'))\n",
    "print(lookup(trie, 'souris'))\n",
    "print(lookup(trie, 'cheval'))\n",
    "print(lookup(trie, 'che'))\n",
    "print(lookup(trie, 'chev'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6\n",
    "\n",
    "Write a recursive function `pp_trie` that pretty prints a trie in alphabetically sorted order by replacing common prefixes with `'-'` characters.\n",
    "Test your implementation with the following example data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'c': {'h': {'a': {'i': {'r': {'value': 'flesh'}},\n",
      "                   't': {'value': 'cat'}},\n",
      "             'e': {'v': {'a': {'l': {'value': 'horse'}}}},\n",
      "             'i': {'c': {'value': 'stylish'},\n",
      "                   'e': {'n': {'value': 'dog'}}}}},\n",
      " 's': {'o': {'u': {'r': {'i': {'s': {'value': 'mouse'}}}}}}}\n"
     ]
    }
   ],
   "source": [
    "trie = {}\n",
    "insert(trie, 'chat', 'cat')\n",
    "insert(trie, 'souris', 'mouse')\n",
    "insert(trie, 'chien', 'dog')\n",
    "insert(trie, 'chair', 'flesh')\n",
    "insert(trie, 'chic', 'stylish')\n",
    "insert(trie, 'cheval','horse') \n",
    "trie = dict(trie)             \n",
    "pprint.pprint(trie, width=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pp_trie(trie, s=\"\"):\n",
    "    first=True\n",
    "    for k,v in sorted(trie.items(), key=lambda x:x[0]):\n",
    "        if isinstance(v, dict):\n",
    "            if first:\n",
    "                prefix=s+k\n",
    "                first=False\n",
    "            else:\n",
    "                prefix='-'*len(s)+k\n",
    "            pp_trie(v, prefix)\n",
    "        else:\n",
    "            print(s, \":\", v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chair : flesh\n",
      "---t : cat\n",
      "--eval : horse\n",
      "--ic : stylish\n",
      "---en : dog\n",
      "souris : mouse\n"
     ]
    }
   ],
   "source": [
    "pp_trie(trie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    chair: flesh\n",
    "    ---t: cat\n",
    "    --eval: horse\n",
    "    --ic: stylish\n",
    "    ---en: dog\n",
    "    souris: mouse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7\n",
    "\n",
    "The *Catalan numbers* arise in many applications of combinatorial mathematics, including the counting of parse trees. The series can be defined as follows: $C_0 = 1$, and $C_{n+1} = \\sum_{i=0}^{n}C_iC_{n-i}$ for $n\\geq{0}$.\n",
    "\n",
    "Write:\n",
    "\n",
    "a) a recursive function `cn(n)` to compute the $n$th Catalan number $C_{n}$,  \n",
    "b) a corresponding function `cn2(n)` that uses dynamic programming by storing calculated solutions in a lookup table,  \n",
    "c) a function `cn3(n)`, which is identical to `cn(n)` but uses a `memoize` decorator.\n",
    "\n",
    "Test your functions first by calculating the Catalan numbers $C_0\\dots C_{16}$ and then by using the `timeit` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "#a recursive function cn(n) to compute the ùëõth Catalan number  \n",
    "\n",
    "def cn(n):\n",
    "    if n == 0 or n == 1:\n",
    "        return 1\n",
    "    result = 0\n",
    "    for i in range(n):\n",
    "        result += cn(i) * cn(n - i - 1)\n",
    "    return result\n",
    "\n",
    "# a corresponding function cn2(n) that uses dynamic programming by storing calculated solutions in a lookup table\n",
    "\n",
    "def cn2(n):\n",
    "    if n == 0:\n",
    "        return 1\n",
    "    catalan = [0] * (n + 1)\n",
    "    catalan[0] = 1\n",
    "    for i in range(1, n + 1):\n",
    "        for j in range(i):\n",
    "            catalan[i] += catalan[j] * catalan[i - j - 1]\n",
    "    return catalan[n]\n",
    "\n",
    "# a function cn3(n), which is identical to cn(n) but uses a memoize decorator\n",
    "\n",
    "from functools import lru_cache\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def cn3(n):\n",
    "    if n == 0:\n",
    "        return 1\n",
    "    result = 0\n",
    "    for i in range(n):\n",
    "        result += cn3(i) * cn3(n - i - 1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.05024200002663\n",
      "0.00018630002159625292\n",
      "5.249993409961462e-05\n"
     ]
    }
   ],
   "source": [
    "print(timeit.timeit(\"cn(16)\", setup=\"from __main__ import cn\", number=5))\n",
    "print(timeit.timeit(\"cn2(16)\", setup=\"from __main__ import cn2\", number=5))\n",
    "print(timeit.timeit(\"cn3(16)\", setup=\"from __main__ import cn3\", number=5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
