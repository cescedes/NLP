{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing\n",
    "\n",
    "## Exercise Sheet 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports for all exercises\n",
    "import nltk\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Write a name gender classifier using the Names Corpus, the `apply_features` function, shuffling, and a test set of 500 instances. Use the following features:\n",
    "\n",
    "a) first letter;  \n",
    "b) last letter;  \n",
    "c) last two letters;  \n",
    "d) length;  \n",
    "e) for each letter one feature, which is true if the name contains the letter.\n",
    "\n",
    "Use the `NaiveBayesClassifier`, calculate the accuracy, and display the 10 most informative features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.782\n",
      "Most Informative Features\n",
      "             last_letter = 'k'              male : female =     43.5 : 1.0\n",
      "             last_letter = 'a'            female : male   =     34.6 : 1.0\n",
      "             last_letter = 'f'              male : female =     14.5 : 1.0\n",
      "             last_letter = 'p'              male : female =     11.8 : 1.0\n",
      "             last_letter = 'v'              male : female =     11.1 : 1.0\n",
      "             last_letter = 'd'              male : female =     10.4 : 1.0\n",
      "             last_letter = 'o'              male : female =      8.5 : 1.0\n",
      "             last_letter = 'm'              male : female =      8.2 : 1.0\n",
      "        last_two_letters = 'o'              male : female =      7.5 : 1.0\n",
      "        last_two_letters = 'u'              male : female =      7.2 : 1.0\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import names\n",
    "from nltk.classify import apply_features\n",
    "\n",
    "labeled_names = ([(name, 'male') for name in names.words('male.txt')] + \n",
    "                 [(name, 'female') for name in names.words('female.txt')])\n",
    "\n",
    "# feature extractor\n",
    "def gender_features(name):\n",
    "    features = {}\n",
    "    features[\"first_letter\"] = name[0].lower() \n",
    "    features[\"last_letter\"] = name[-1].lower()  \n",
    "    features[\"last_two_letters\"] = name[-2].lower()\n",
    "    features[\"length\"] = len(name)\n",
    "    # for each letter, construct a feature name. (e.g. for the letter 'a', it creates a feature named 'contains_a')\n",
    "    # it checks whether the current letter exists in the name\n",
    "    # if the letter is present in the name, the value of the feature is set to True; otherwise, False.\n",
    "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        features[f'contains_{letter}'] = letter in name.lower()\n",
    "    return features\n",
    "\n",
    "random.shuffle(labeled_names)\n",
    "\n",
    "# split data and apply features\n",
    "train_set = apply_features(gender_features, labeled_names[500:])\n",
    "test_set = apply_features(gender_features, labeled_names[:500])\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "# calculate the accuracy\n",
    "print(nltk.classify.accuracy(classifier, test_set))\n",
    "\n",
    "# display the 10 most informative features\n",
    "classifier.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This listing shows that the names in the training set that end in \"a\" are female 33 times more often than they are male, but names that end in \"k\" are male 31 times more often than they are female. \n",
    "These ratios are known as likelihood ratios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "The Senseval 2 Corpus contains data intended to train word-sense disambiguation classifiers. Using this dataset, build a `NaiveBayesClassifier` that predicts the correct sense tag for a given instance for the word \"hard\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.classify import apply_features\n",
    "\n",
    "# feature extractor\n",
    "# extract the preceding and following words of the word \"hard\" in an instance\n",
    "def features(inst):\n",
    "    p = inst.position   # the inst.position attribute to find the position of \"hard\"\n",
    "    # retrieve the context words\n",
    "    features = {\n",
    "        'prev_word': inst.context[p-1],\n",
    "        'next_word': inst.context[p+1]\n",
    "    }\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8937644341801386\n",
      "Accuracy: 0.9030023094688222\n",
      "Accuracy: 0.9237875288683602\n",
      "Accuracy: 0.8568129330254042\n",
      "Accuracy: 0.8891454965357968\n",
      "Accuracy: 0.9076212471131639\n",
      "Accuracy: 0.9145496535796767\n",
      "Accuracy: 0.9191685912240185\n",
      "Accuracy: 0.8891454965357968\n",
      "Accuracy: 0.9076212471131639\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import senseval\n",
    "\n",
    "instances = senseval.instances('hard.pos')\n",
    "labeled_instances = [(inst, inst.senses) for inst in instances]\n",
    "\n",
    "num_iterations = 10\n",
    "accuracies = []\n",
    " \n",
    "for _ in range(num_iterations): \n",
    "    size = int(len(labeled_instances) * 0.1)\n",
    "    random.shuffle(labeled_instances)\n",
    "    train_set = apply_features(features, labeled_instances[size:])\n",
    "    test_set = apply_features(features, labeled_instances[:size])\n",
    "    classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "    accuracy = nltk.classify.accuracy(classifier, test_set)\n",
    "    accuracies.append(accuracy)\n",
    "    print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the preceding and following word as features. They can be calculated by retrieving the position of the word \"hard\" as `p=inst.position` and then accessing `inst.context[p-1]` and `inst.context[p+1]`.\n",
    "\n",
    "Run 10 iterations by reshuffling the instances and printing the individual accuracies. Finally, print the average accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.9004618937644342\n"
     ]
    }
   ],
   "source": [
    "average_accuracy = sum(accuracies) / num_iterations\n",
    "print(\"Average Accuracy:\", average_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "The synonyms \"strong\" and \"powerful\" pattern differently. Use the tagged Brown corpus with the universal tagset to first list the nouns which follow \"strong\" vs. \"powerful\". Write for this a function `next_noun(word, tagged_text)` which returns the list of nouns that follow `word` in the `tagged_text`. Build then a `NaiveBayesClassifier` that predicts when each word should be used by using the function `apply_features` and the following noun as single feature.\n",
    "\n",
    "Run 10 iterations by reshuffling the instances and printing the individual accuracies. Finally, print the average accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "\n",
    "tagged_brown = brown.tagged_sents(tagset='universal')\n",
    "\n",
    "# extract next nouns following a word\n",
    "def next_noun(word, tagged_text):\n",
    "    nouns = []\n",
    "    for sentence in tagged_text:\n",
    "        for i in range(len(sentence) - 1):\n",
    "            if sentence[i][0].lower() == word:\n",
    "                if sentence[i+1][1] == 'NOUN':\n",
    "                    nouns.append(sentence[i+1][0].lower())\n",
    "    return nouns\n",
    "\n",
    "# labeled instances for 'strong' and 'powerful' based on next nouns\n",
    "labeled_instances = []\n",
    "for word in ['strong', 'powerful']:\n",
    "    next_nouns = next_noun(word, tagged_brown)\n",
    "    for noun in next_nouns:\n",
    "        labeled_instances.append(({'next_noun': noun}, word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7857142857142857\n",
      "Accuracy: 0.7857142857142857\n",
      "Accuracy: 0.7857142857142857\n",
      "Accuracy: 0.7142857142857143\n",
      "Accuracy: 0.6428571428571429\n",
      "Accuracy: 0.7857142857142857\n",
      "Accuracy: 0.6428571428571429\n",
      "Accuracy: 0.7142857142857143\n",
      "Accuracy: 0.7857142857142857\n",
      "Accuracy: 0.9285714285714286\n",
      "Average Accuracy: 0.7571428571428572\n"
     ]
    }
   ],
   "source": [
    "num_iterations = 10\n",
    "accuracies = []\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "    random.shuffle(labeled_instances)\n",
    "    size = int(len(labeled_instances) * 0.1)\n",
    "\n",
    "    train_set = apply_features(lambda x: x, labeled_instances[size:])\n",
    "    test_set = apply_features(lambda x: x, labeled_instances[:size])\n",
    "\n",
    "    classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "    accuracy = nltk.classify.accuracy(classifier, test_set)\n",
    "    accuracies.append(accuracy)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "average_accuracy = sum(accuracies) / num_iterations\n",
    "print(\"Average Accuracy:\", average_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "Based on the Movie Reviews document classifier discussed in this chapter, build a new `NaiveBayesClassifier`. Tag first the Movie Reviews Corpus using the combined tagger from the previous chapter stored in `t2.pkl`. Filter the tagged words to contain only words for the tags `['JJ', 'JJR', 'JJS', 'RB', 'NN', 'NNS', 'VB', 'VBN', 'VBG', 'VBZ', 'VBD', 'QL']` as well as only alphabetic tokens with at least three characters. Convert the words to lowercase. Use the most common 5000 words as `word_features` in the function `document_features`. \n",
    "\n",
    "Run 10 iterations by reshuffling the instances and printing the accuracy and 5 most informative features for each iteration. Finally, print the average accuracy.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_tagged_sents = brown.tagged_sents(categories='news')\n",
    "size = int(len(brown_tagged_sents) * 0.9)\n",
    "train_sents = brown_tagged_sents[:size]\n",
    "test_sents = brown_tagged_sents[size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = nltk.DefaultTagger('NN')\n",
    "t1 = nltk.UnigramTagger(train_sents, backoff=t0)\n",
    "t2 = nltk.BigramTagger(train_sents, backoff=t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import dump, load\n",
    "output = open('t2.pkl', 'wb')\n",
    "dump(t2, output, -1)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 - Accuracy: 80.00%\n",
      "Top 5 most informative features:\n",
      "Most Informative Features\n",
      "             outstanding = True              pos : neg    =     11.0 : 1.0\n",
      "               ludicrous = True              neg : pos    =     10.4 : 1.0\n",
      "               insulting = True              neg : pos    =     10.2 : 1.0\n",
      "                   sucks = True              neg : pos    =      9.8 : 1.0\n",
      "                chilling = True              pos : neg    =      9.0 : 1.0\n",
      "\n",
      "Iteration 2 - Accuracy: 77.00%\n",
      "Top 5 most informative features:\n",
      "Most Informative Features\n",
      "             outstanding = True              pos : neg    =     11.4 : 1.0\n",
      "               insulting = True              neg : pos    =     10.6 : 1.0\n",
      "                   sucks = True              neg : pos    =     10.6 : 1.0\n",
      "                  hudson = True              neg : pos    =     10.3 : 1.0\n",
      "               ludicrous = True              neg : pos    =      9.9 : 1.0\n",
      "\n",
      "Iteration 3 - Accuracy: 83.00%\n",
      "Top 5 most informative features:\n",
      "Most Informative Features\n",
      "               stupidity = True              neg : pos    =     12.5 : 1.0\n",
      "             outstanding = True              pos : neg    =     10.9 : 1.0\n",
      "               insulting = True              neg : pos    =     10.8 : 1.0\n",
      "                  hudson = True              neg : pos    =     10.6 : 1.0\n",
      "               ludicrous = True              neg : pos    =     10.4 : 1.0\n",
      "\n",
      "Iteration 4 - Accuracy: 78.00%\n",
      "Top 5 most informative features:\n",
      "Most Informative Features\n",
      "               ludicrous = True              neg : pos    =     13.7 : 1.0\n",
      "               stupidity = True              neg : pos    =     12.1 : 1.0\n",
      "             outstanding = True              pos : neg    =     11.4 : 1.0\n",
      "               insulting = True              neg : pos    =     10.6 : 1.0\n",
      "                   sucks = True              neg : pos    =      9.8 : 1.0\n",
      "\n",
      "Iteration 5 - Accuracy: 76.00%\n",
      "Top 5 most informative features:\n",
      "Most Informative Features\n",
      "             outstanding = True              pos : neg    =     11.4 : 1.0\n",
      "               insulting = True              neg : pos    =     11.0 : 1.0\n",
      "               ludicrous = True              neg : pos    =     10.7 : 1.0\n",
      "               marvelous = True              pos : neg    =     10.2 : 1.0\n",
      "                   sucks = True              neg : pos    =     10.2 : 1.0\n",
      "\n",
      "Iteration 6 - Accuracy: 77.00%\n",
      "Top 5 most informative features:\n",
      "Most Informative Features\n",
      "               ludicrous = True              neg : pos    =     15.0 : 1.0\n",
      "               stupidity = True              neg : pos    =     12.6 : 1.0\n",
      "             outstanding = True              pos : neg    =     10.6 : 1.0\n",
      "                  hudson = True              neg : pos    =     10.3 : 1.0\n",
      "               insulting = True              neg : pos    =     10.2 : 1.0\n",
      "\n",
      "Iteration 7 - Accuracy: 85.00%\n",
      "Top 5 most informative features:\n",
      "Most Informative Features\n",
      "             outstanding = True              pos : neg    =     11.0 : 1.0\n",
      "               ludicrous = True              neg : pos    =     10.9 : 1.0\n",
      "                  hudson = True              neg : pos    =     10.5 : 1.0\n",
      "               insulting = True              neg : pos    =     10.0 : 1.0\n",
      "                   sucks = True              neg : pos    =      9.6 : 1.0\n",
      "\n",
      "Iteration 8 - Accuracy: 83.00%\n",
      "Top 5 most informative features:\n",
      "Most Informative Features\n",
      "              schumacher = True              neg : pos    =     12.3 : 1.0\n",
      "               stupidity = True              neg : pos    =     11.8 : 1.0\n",
      "             outstanding = True              pos : neg    =     11.4 : 1.0\n",
      "               insulting = True              neg : pos    =     10.6 : 1.0\n",
      "               ludicrous = True              neg : pos    =     10.4 : 1.0\n",
      "\n",
      "Iteration 9 - Accuracy: 76.00%\n",
      "Top 5 most informative features:\n",
      "Most Informative Features\n",
      "               insulting = True              neg : pos    =     10.8 : 1.0\n",
      "             outstanding = True              pos : neg    =     10.8 : 1.0\n",
      "               ludicrous = True              neg : pos    =     10.3 : 1.0\n",
      "                   sucks = True              neg : pos    =     10.1 : 1.0\n",
      "                  hudson = True              neg : pos    =      9.5 : 1.0\n",
      "\n",
      "Iteration 10 - Accuracy: 77.00%\n",
      "Top 5 most informative features:\n",
      "Most Informative Features\n",
      "               stupidity = True              neg : pos    =     12.5 : 1.0\n",
      "                  seagal = True              neg : pos    =     12.3 : 1.0\n",
      "             outstanding = True              pos : neg    =     10.9 : 1.0\n",
      "               ludicrous = True              neg : pos    =     10.6 : 1.0\n",
      "               insulting = True              neg : pos    =     10.5 : 1.0\n",
      "\n",
      "Average Accuracy over 10 iterations: 79.20%\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import movie_reviews\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.classify.util import accuracy\n",
    "import pickle\n",
    "\n",
    "with open('t2.pkl', 'rb') as f:\n",
    "    combined_tagger = pickle.load(f)\n",
    "\n",
    "# the list of allowed POS tags and the minimum token length\n",
    "allowed_tags = ['JJ', 'JJR', 'JJS', 'RB', 'NN', 'NNS', 'VB', 'VBN', 'VBG', 'VBZ', 'VBD', 'QL']\n",
    "min_token_length = 3\n",
    "\n",
    "# extract features from a document\n",
    "def document_features(document, word_features):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features[word] = (word in document_words)\n",
    "    return features\n",
    "\n",
    "# prepare the movie reviews corpus and filter it\n",
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "             for category in movie_reviews.categories()\n",
    "             for fileid in movie_reviews.fileids(category)]\n",
    "\n",
    "filtered_documents = []\n",
    "for (words, category) in documents:\n",
    "    tagged_words = combined_tagger.tag(words)\n",
    "    filtered_words = [word.lower() for (word, tag) in tagged_words if tag in allowed_tags and len(word) >= min_token_length]\n",
    "    filtered_documents.append((filtered_words, category))\n",
    "\n",
    "# a list of most common 5000 words as word_features\n",
    "all_words = nltk.FreqDist(w.lower() for w in movie_reviews.words())\n",
    "word_features = list(all_words)[:5000]\n",
    "\n",
    "num_iterations = 10\n",
    "total_accuracy = 0\n",
    "\n",
    "for i in range(num_iterations):\n",
    "    random.shuffle(filtered_documents)\n",
    "    featuresets = [(document_features(d, word_features), c) for (d, c) in filtered_documents]\n",
    "    train_set, test_set = featuresets[100:], featuresets[:100]  # 100 test instances\n",
    "\n",
    "    classifier = NaiveBayesClassifier.train(train_set)\n",
    "    acc = accuracy(classifier, test_set)\n",
    "    total_accuracy += acc\n",
    "\n",
    "    print(f\"Iteration {i + 1} - Accuracy: {acc:.2%}\")\n",
    "    print(\"Top 5 most informative features:\")\n",
    "    classifier.show_most_informative_features(5)\n",
    "    print()\n",
    "\n",
    "# Calculate and print the average accuracy\n",
    "average_accuracy = total_accuracy / num_iterations\n",
    "print(f\"Average Accuracy over {num_iterations} iterations: {average_accuracy:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "The PP Attachment Corpus is a corpus describing prepositional phrase attachment decisions. Each instance in the training corpus is encoded as a `PPAttachment` object:\n",
    "\n",
    "    from nltk.corpus import ppattach\n",
    "    ppattach.attachments('training')\n",
    "    \n",
    "        [PPAttachment(sent='0', verb='join', noun1='board',\n",
    "            prep='as', noun2='director', attachment='V'),\n",
    "        PPAttachment(sent='1', verb='is', noun1='chairman',\n",
    "            prep='of', noun2='N.V.', attachment='N'),\n",
    "        ...]\n",
    "\n",
    "    inst = ppattach.attachments('training')[1]\n",
    "    (inst.noun1, inst.prep, inst.noun2)\n",
    "    \n",
    "        ('chairman', 'of', 'N.V.')\n",
    "\n",
    "In the same way, `ppattach.attachments('test')` accesses the test instances. Select only the instances where `inst.attachment` is `'N'`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import ppattach\n",
    "nattach = [inst for inst in ppattach.attachments('training')\n",
    "               if inst.attachment == 'N']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this sub-corpus, build a `NaiveBayesClassifier` that attempts to predict which preposition is used to connect a given pair of nouns. For example, given the pair of nouns \"team\" and \"researchers\", the classifier should predict the preposition \"of\". \n",
    "\n",
    "Write for this purpose a function `prepare_featuresets(subcorpus)`, where `subcorpus` is either the string \"training\" or \"test\" to return the training set or the test set. \n",
    "\n",
    "Print the achieved accuracy as well as the result of `classifier.classify({ 'noun1': 'team', 'noun2': 'researchers' })`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5690032858707558\n",
      "Prediction for ('team', 'researchers'): of\n"
     ]
    }
   ],
   "source": [
    "def prepare_featuresets(subcorpus):\n",
    "    # select the subcorpus (either 'training' or 'test')\n",
    "    instances = ppattach.attachments(subcorpus)\n",
    "\n",
    "    # create a list of feature sets and labels\n",
    "    featuresets = []\n",
    "    for inst in instances:\n",
    "        if inst.attachment == 'N':\n",
    "            features = {'noun1': inst.noun1, 'noun2': inst.noun2}\n",
    "            label = inst.prep\n",
    "            featuresets.append((features, label))\n",
    "\n",
    "    return featuresets\n",
    "\n",
    "training_set = prepare_featuresets('training')\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "\n",
    "test_set = prepare_featuresets('test')\n",
    "accuracy = nltk.classify.accuracy(classifier, test_set)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "noun1 = 'team'\n",
    "noun2 = 'researchers'\n",
    "prediction = classifier.classify({'noun1': noun1, 'noun2': noun2})\n",
    "print(\"Prediction for ('{}', '{}'):\".format(noun1, noun2), prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
